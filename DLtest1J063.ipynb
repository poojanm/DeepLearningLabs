{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLtest1J063.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xetc2-Rq6W_R",
        "colab_type": "text"
      },
      "source": [
        "Deep Learning Test\n",
        "\n",
        "Poojan Mehta\n",
        "\n",
        "J063"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVCJVKDsun_E",
        "colab_type": "code",
        "outputId": "7ce0fd6c-5fe5-4536-acd9-a48067ade703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history =model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2239 - acc: 0.9318 - val_loss: 0.1046 - val_acc: 0.9675\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0842 - acc: 0.9740 - val_loss: 0.0866 - val_acc: 0.9747\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0544 - acc: 0.9827 - val_loss: 0.0815 - val_acc: 0.9788\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0398 - acc: 0.9873 - val_loss: 0.0792 - val_acc: 0.9784\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0299 - acc: 0.9911 - val_loss: 0.0811 - val_acc: 0.9795\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.0776 - val_acc: 0.9816\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.0926 - val_acc: 0.9804\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0138 - acc: 0.9956 - val_loss: 0.1033 - val_acc: 0.9799\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0930 - val_acc: 0.9816\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.0953 - val_acc: 0.9830\n",
            "Test loss: 0.09532487297712985\n",
            "Test accuracy: 0.983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EauZxBhAzFYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFJXFz6u6N6k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfjfDGPZuyTd",
        "colab_type": "code",
        "outputId": "2ad1a750-573a-4835-9fb0-aa45d2386215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0875 - val_acc: 0.9838\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0856 - val_acc: 0.9841\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0846 - val_acc: 0.9842\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0841 - val_acc: 0.9841\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0837 - val_acc: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0833 - val_acc: 0.9845\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0831 - val_acc: 0.9844\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0829 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0827 - val_acc: 0.9845\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 9.5297e-04 - acc: 0.9999 - val_loss: 0.0826 - val_acc: 0.9844\n",
            "Test loss: 0.08258774196938827\n",
            "Test accuracy: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl9-1CBhyjkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4c0EwHc1BLf",
        "colab_type": "code",
        "outputId": "5a135282-81f8-4300-c474-48d3aaeba550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.1015 - val_acc: 0.9822\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.1111 - val_acc: 0.9812\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1113 - val_acc: 0.9838\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.1105 - val_acc: 0.9838\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1187 - val_acc: 0.9823\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1110 - val_acc: 0.9849\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.1308 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.1337 - val_acc: 0.9832\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1410 - val_acc: 0.9812\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1309 - val_acc: 0.9832\n",
            "Test loss: 0.13088987769798913\n",
            "Test accuracy: 0.9832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk098xd91CTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZFPp3DF1Xdc",
        "colab_type": "code",
        "outputId": "6c36c07e-7e94-46ae-ee76-627e3d3dcd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0324 - acc: 0.9955 - val_loss: 0.1178 - val_acc: 0.9834\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 5.6491e-04 - acc: 0.9999 - val_loss: 0.1168 - val_acc: 0.9846\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 3.1539e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9846\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.9660e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9847\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.9179e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8901e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9847\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8701e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9846\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8545e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9846\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8421e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8316e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9843\n",
            "Test loss: 0.11571174743729577\n",
            "Test accuracy: 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTZUb5or1Yv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPQpJY6m1a-7",
        "colab_type": "code",
        "outputId": "a9a0dd1c-0de8-44d6-8db1-0a2e4248808c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 2.8231e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9843\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.8034e-04 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9846\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7895e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9845\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7790e-04 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7710e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7643e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7589e-04 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9846\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7541e-04 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9848\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7502e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9847\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7467e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9847\n",
            "Test loss: 0.11693391883599136\n",
            "Test accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEDSzxq-1coQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utekwjt91kPK",
        "colab_type": "code",
        "outputId": "d99c3569-9c7a-433c-99d9-6bf74b9b9ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.0174 - acc: 0.9957 - val_loss: 0.1294 - val_acc: 0.9791\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0147 - acc: 0.9963 - val_loss: 0.1197 - val_acc: 0.9794\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0108 - acc: 0.9971 - val_loss: 0.1258 - val_acc: 0.9799\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.1197 - val_acc: 0.9792\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.1193 - val_acc: 0.9801\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0121 - acc: 0.9966 - val_loss: 0.1412 - val_acc: 0.9804\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.1159 - val_acc: 0.9825\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1278 - val_acc: 0.9778\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.1062 - val_acc: 0.9821\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0128 - acc: 0.9966 - val_loss: 0.1174 - val_acc: 0.9805\n",
            "Test loss: 0.11739989918780366\n",
            "Test accuracy: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jff--Hub1trV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AChgn412JW",
        "colab_type": "code",
        "outputId": "dd1dce78-10c3-4ca3-da1e-e6a567aadb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0358 - acc: 0.9925 - val_loss: 0.1204 - val_acc: 0.9782\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0200 - acc: 0.9945 - val_loss: 0.1266 - val_acc: 0.9786\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.1074 - val_acc: 0.9797\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0205 - acc: 0.9942 - val_loss: 0.1188 - val_acc: 0.9794\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0154 - acc: 0.9955 - val_loss: 0.1291 - val_acc: 0.9790\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0190 - acc: 0.9948 - val_loss: 0.1168 - val_acc: 0.9779\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0172 - acc: 0.9951 - val_loss: 0.1139 - val_acc: 0.9808\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0219 - acc: 0.9941 - val_loss: 0.1036 - val_acc: 0.9795\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.1060 - val_acc: 0.9817\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.1267 - val_acc: 0.9799\n",
            "Test loss: 0.12672712212707288\n",
            "Test accuracy: 0.9799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC18s6l01mKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em_gBPle1r_d",
        "colab_type": "code",
        "outputId": "b6c83675-01c2-4909-b6aa-3ed1cfd69227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 2.7163e-04 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9852\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6899e-04 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6886e-04 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9853\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6882e-04 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9852\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9852\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1252 - val_acc: 0.9853\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9856\n",
            "Test loss: 0.12601937637878108\n",
            "Test accuracy: 0.9856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG4x8GAX2JIk",
        "colab_type": "text"
      },
      "source": [
        "Adamax is the best optimizer.\n",
        "Next part is done using adamax model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q8g8SPK5snN",
        "colab_type": "text"
      },
      "source": [
        "BATCH_SIZE = 128 \n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GSGWISt145u",
        "colab_type": "code",
        "outputId": "8932af76-f2a9-459b-c595-20d8f5dc10cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZC5wxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAd5ElEQVR4nO3df5RdZX3v8fcnM5PMJJn8YDIgMIFE\nguIgCjiNVryiBDH4g7RXlMRSIWJTXEXspbTGe+8SiPUWXCpSkquNAvJDDRRkmVYxYrm31xaFTEIE\nQ6DECGQglGQgCYH8muR7/9h7yMmZZ5KZZHbOZM7ntdZZZ+/n2fuc7zkreT5nP3vPOYoIzMzMyg2r\ndAFmZjY4OSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmB0HSJEkhqbYP214s6d8O9nHMDhUH\nhFUNSU9L2iFpQln7I/ngPKkylZkNTg4Iqza/B2Z1r0g6BRhZuXLMBi8HhFWb24FPlaxfBNxWuoGk\nsZJuk7Re0jOS/qekYXlfjaSvSdogaQ3w4cS+N0laJ+k5SX8rqaa/RUo6RtJiSS9JWi3pz0r6pkpq\nl7RZ0n9K+kbeXi/pDkmdkjZKWirpqP4+t1k3B4RVm18DYyS9JR+4ZwJ3lG1zIzAWeCNwJlmgzM77\n/gz4CHAa0AacX7bv94AuYEq+zTnAZw6gzkVAB3BM/hz/S9JZed8NwA0RMQY4Abgrb78or3si0ARc\nCmw9gOc2AxwQVp26jyI+AKwCnuvuKAmNL0bEKxHxNPB14E/zTT4BfDMi1kbES8Dflex7FPAh4C8j\n4tWIeBG4Pn+8PpM0ETgD+EJEbIuIFcB32XPksxOYImlCRGyJiF+XtDcBUyJiV0Qsi4jN/Xlus1IO\nCKtGtwOfBC6mbHoJmADUAc+UtD0DHJsvHwOsLevrdny+77p8imcj8A/Akf2s7xjgpYh4pZcaLgHe\nBDyRTyN9pOR1LQEWSXpe0lcl1fXzuc1e54CwqhMRz5CdrP4Q8KOy7g1kn8SPL2k7jj1HGevIpnBK\n+7qtBbYDEyJiXH4bExEn97PE54EjJDWmaoiIpyJiFlnwXAfcLWlUROyMiGsiohV4N9lU2KcwO0AO\nCKtWlwBnRcSrpY0RsYtsTv8rkholHQ9cwZ7zFHcBl0tqkTQemFuy7zrg58DXJY2RNEzSCZLO7E9h\nEbEWeBD4u/zE89vyeu8AkHShpOaI2A1szHfbLen9kk7Jp8k2kwXd7v48t1kpB4RVpYj4XUS099L9\nOeBVYA3wb8APgJvzvu+QTeP8BlhOzyOQTwHDgceBl4G7gaMPoMRZwCSyo4l7gasi4hd533RgpaQt\nZCesZ0bEVuAN+fNtJju38q9k005mB0T+wSAzM0vxEYSZmSU5IMzMLMkBYWZmSQ4IMzNLGjJfLTxh\nwoSYNGlSpcswMzusLFu2bENENKf6hkxATJo0ifb23q5aNDOzFEnP9NbnKSYzM0tyQJiZWZIDwszM\nkobMOYiUnTt30tHRwbZt2ypdyiFTX19PS0sLdXX+Ek8zOzhDOiA6OjpobGxk0qRJSKp0OYWLCDo7\nO+no6GDy5MmVLsfMDnNDeopp27ZtNDU1VUU4AEiiqampqo6YzKw4QzoggKoJh27V9nrNrDhDeorJ\nzOywsmsn7HwNdm6Drq3Z/c7XoGsb7Ny65750uWsbjGqGttn7f/x+ckAUqLOzk2nTpgHwwgsvUFNT\nQ3Nz9geLDz/8MMOHD9/vY8yePZu5c+fy5je/udBazWw/du+C7Zth22bYtilb3v5KyWBdNrCn2noM\n9mVtsevAamuZ6oA43DQ1NbFixQoArr76akaPHs2VV1651zYRQUQwbFh6tu+WW24pvE6zIS8iG4hL\nB/dtm2Hbxnx5U6Jv0959O17Z//N0Uw3UNUBtPdSNhLr6fDlvazgib2vI7utG5v3dbQ0l+5c/Tvk+\nDTCsppC3zQFRAatXr+a8887jtNNO45FHHuH+++/nmmuuYfny5WzdupULLriAL33pSwC85z3vYf78\n+bz1rW9lwoQJXHrppdx3332MHDmSH//4xxx55JEVfjVmBYvIPmFvfyW7bdtUcp8azDel+3Z37ft5\nhtVC/VgYMQbqx2TLo94I9eP2rI/I77vXh49OD9w1Q+My86oJiGv+aSWPP795QB+z9ZgxXPXR/v4e\nfeaJJ57gtttuo62tDYBrr72WI444gq6uLt7//vdz/vnn09rautc+mzZt4swzz+Taa6/liiuu4Oab\nb2bu3LmphzervAjY8eqegX37K3umZfZa3ly2TWLb/Q3uAMMb9x7IRx8FE97Uc1AfMSY96Nc1gC/y\n2EvVBMRgc8IJJ7weDgA//OEPuemmm+jq6uL555/n8ccf7xEQDQ0NnHvuuQC84x3v4Je//OUhrdmq\nSEQ2QG/dmE3DdN93f3ovH8S3JQb5Ha9A7N7/c9U2wIjGvW/jju/ZNqIxG8y7l8sH/YKmWapZ1QTE\ngX7SL8qoUaNeX37qqae44YYbePjhhxk3bhwXXnhh8m8ZSk9q19TU0NXVh09VVr1274btm3oO8nvd\nb0r3bdu0/8F9+OieA3jjUXsP4nsN7Kn2xiEzHTMUVU1ADGabN2+msbGRMWPGsG7dOpYsWcL06dMr\nXZZVWgR0bd/zSb3XQb5sYH99eTMQvT/+sDpoGJdNtzSMg5EToGnKnvX6sSXLJff1Y7Jw8Cf2Ia/Q\ngJA0HbgBqAG+GxHXlvW/F/gm8DZgZkTcnbefCnwLGAPsAr4SEXcWWWslnX766bS2tnLSSSdx/PHH\nc8YZZ1S6JDsYEdkli/ucYy9p6zE9Uzr3vnPfz1UzYu8BfPQboPmkXgb2sXu31Y30nLvtkyL28Qnj\nYB5YqgH+A/gA0AEsBWZFxOMl20wiC4ErgcUlAfEmICLiKUnHAMuAt0TExt6er62tLcp/MGjVqlW8\n5S1vGciXdVio1td90HZ1ZfPm21+B7Vtgx5Z8Ln1LzwE8NedeOrj35Xr22vq+T8OMaEwP+nX1xb8v\nNqRJWhYRbam+Io8gpgKrI2JNXsQiYAbwekBExNN5316TnRHxHyXLz0t6EWgGeg0Iq0LdV8ns2JIP\n6GUD++uDe/lgvyW9T1cfv8OqbmTPgX3UhH3MvedX15S2DR8Ntfv/Q0mzSioyII4F1pasdwDv7O+D\nSJoKDAd+l+ibA8wBOO644w6sSquc3buy+fKtL8FrL/W8775iptfBfQv7nGMvNXx0yUnVfHncxLyt\npK97fURjdtnkiLITscMbocan7qw6DOp/6ZKOBm4HLoroeUlFRCwEFkI2xXSIy7NSO17rZaB/ed8B\n0NsAr5r88sXGPQP3yKb88sfRewbv1wf0Mb0P9nWjoJe/VDez3hUZEM8BE0vWW/K2PpE0BvgJ8D8i\n4tcDXJv1ZtfObH69t0F968t7L3f37Wt6Zvjo7KsFRo6HhvEw7jgYeUTeVn4/PruvH+sTqGYVVmRA\nLAVOlDSZLBhmAp/sy46ShgP3Ard1n7i2fYjIrlnfvSu779oOv3sgm4Yp/aOl7SUnYEtPqpbO2e9r\noFdNNsB3D+bjjoOjT90zqCcH/fFQO+LQvRdmNmAKC4iI6JJ0GbCE7DLXmyNipaR5QHtELJb0B2RB\nMB74qKRrIuJk4BPAe4EmSRfnD3lxRKwoqt6K2r0r++S+e2f2x02xK7ullrtDYK/+stm3LS/CPZ/o\n+Tw1I/bMwXefLG08umfbiMb0p/oRYzxVY1ZFCj0HERE/BX5a1valkuWlZFNP5fvdAdxRZG2HQueG\n9UybdjYQvPDCf1JTM4zmpiOA4OEl/8jwGmWhsM+/WBU3L/oxH/rA+3jDUUdmn+KH1YCG5/fD8rZh\ne/o2BMz+2d6Dvq+aMbN+GtQnqQetiGxg37Vzzyf/0vv81hS7WHHf9wC4+uvfZvSokVx56UXZVwvU\n1GV/yVozpmS5bu/BXjUgcfOPLuP0s2bwhiP7+LcNdS/A8acX9/rNrCo4IEpFZFM4qcG/PAhSugf5\nmhHZJ/bSIBg5AUaPhaPfDhK33norCxYsYMeOHbz73e9m/vz57N69m9mzZ7NixQoigjlz5nDUUUex\nYsUKLrjgAhoaGvr8Q0NmZgeregLivrnwwmOJjt3ZrzoRWUAkL7tUPpWjfDm/HfVWOOcreQjU7vuq\nm5q6/MhA/Pa3v+Xee+/lwQcfpLa2ljlz5rBo0SJOOOEENmzYwGOPZXVu3LiRcePGceONNzJ//nxO\nPfXUg38fzMz6qHoColf5oK4aGFYaAMP2LNPLwF8zAoaP7Pcz/uIXv2Dp0qWvf9331q1bmThxIh/8\n4Ad58sknufzyy/nwhz/MOeecc0CvyMxsIFRPQJx77f63OUQigk9/+tN8+ctf7tH36KOPct9997Fg\nwQLuueceFi5cWIEKzczA1yxWwNlnn81dd93Fhg0bAOjs7OTZZ59l/fr1RAQf//jHmTdvHsuXLweg\nsbGRV17px+/hmpkNgOo5ghhETjnlFK666irOPvtsdu/eTV1dHd/+9repqanhkksuISKQxHXXXQfA\n7Nmz+cxnPuOT1GZ2SBX2dd+Hmr/ue49qfd1m1n/7+rpvTzGZmVmSA8LMzJKGfEAMlSm0vqq212tm\nxRnSAVFfX09nZ2fVDJoRQWdnJ/X1/hlKMzt4Q/oqppaWFjo6Oli/fn2lSzlk6uvraWnp8f2HZmb9\nNqQDoq6ujsmTJ1e6DDOzw9KQnmIyM7MD54AwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmS\nA8LMzJIKDQhJ0yU9KWm1pLmJ/vdKWi6pS9L5ZX0XSXoqv11UZJ1mZtZTYQEhqQZYAJwLtAKzJLWW\nbfYscDHwg7J9jwCuAt4JTAWukjS+qFrNzKynIo8gpgKrI2JNROwAFgEzSjeIiKcj4lFgd9m+HwTu\nj4iXIuJl4H5geoG1mplZmSID4lhgbcl6R942YPtKmiOpXVJ7NX0hn5nZoXBYn6SOiIUR0RYRbc3N\nzZUux8xsSCkyIJ4DJpast+RtRe9rZmYDoMiAWAqcKGmypOHATGBxH/ddApwjaXx+cvqcvM3MzA6R\nwgIiIrqAy8gG9lXAXRGxUtI8SecBSPoDSR3Ax4F/kLQy3/cl4MtkIbMUmJe3mZnZIaKh8nOcbW1t\n0d7eXukyzMwOK5KWRURbqu+wPkltZmbFcUCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJ\nAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZ\nWZIDwszMkhwQZmaW5IAwM7MkB4SZmSUVGhCSpkt6UtJqSXMT/SMk3Zn3PyRpUt5eJ+lWSY9JWiXp\ni0XWaWZmPRUWEJJqgAXAuUArMEtSa9lmlwAvR8QU4Hrgurz948CIiDgFeAfw593hYWZmh0aRRxBT\ngdURsSYidgCLgBll28wAbs2X7wamSRIQwChJtUADsAPYXGCtZmZWpsiAOBZYW7Lekbclt4mILmAT\n0EQWFq8C64Bnga9FxEsF1mpmZmUG60nqqcAu4BhgMvBXkt5YvpGkOZLaJbWvX7/+UNdoZjakFRkQ\nzwETS9Zb8rbkNvl00ligE/gk8LOI2BkRLwL/DrSVP0FELIyItohoa25uLuAlmJlVryIDYilwoqTJ\nkoYDM4HFZdssBi7Kl88HHoiIIJtWOgtA0ijgXcATBdZqZmZlCguI/JzCZcASYBVwV0SslDRP0nn5\nZjcBTZJWA1cA3ZfCLgBGS1pJFjS3RMSjRdVqZmY9KfvAfvhra2uL9vb2SpdhZnZYkbQsInpM4cPg\nPUltZmYV5oAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeE\nmZklOSDMzCzJAWFmZkl9CghJJ0gakS+/T9LlksYVW5qZmVVSX48g7gF2SZoCLCT7FbgfFFaVmZlV\nXF8DYnf+A0B/DNwYEX8NHF1cWWZmVml9DYidkmaR/TzoP+dtdcWUZGZmg0FfA2I28IfAVyLi95Im\nA7cXV5aZmVVabV82iojHgcsBJI0HGiPiuiILMzOzyurrVUz/V9IYSUcAy4HvSPpGsaWZmVkl9XWK\naWxEbAb+K3BbRLwTOLu4sszMrNL6GhC1ko4GPsGek9RmZjaE9TUg5gFLgN9FxFJJbwSeKq4sMzOr\ntD4FRET8Y0S8LSI+m6+viYiP7W8/SdMlPSlptaS5if4Rku7M+x+SNKmk722SfiVppaTHJNX3/WWZ\nmdnB6utJ6hZJ90p6Mb/dI6llP/vUAAuAc4FWYJak1rLNLgFejogpwPXAdfm+tcAdwKURcTLwPmBn\nP16XmZkdpL5OMd0CLAaOyW//lLfty1RgdX60sQNYBMwo22YGcGu+fDcwTZKAc4BHI+I3ABHRGRG7\n+lirmZkNgL4GRHNE3BIRXfnte0DzfvY5Flhbst6RtyW3yb/KYxPQBLwJCElLJC2X9DepJ5A0R1K7\npPb169f38aWYmVlf9DUgOiVdKKkmv10IdBZYVy3wHuBP8vs/ljStfKOIWBgRbRHR1ty8v7wyM7P+\n6GtAfJrsEtcXgHXA+cDF+9nnObJvfe3Wkrclt8nPO4wlC54O4P9FxIaIeA34KXB6H2s1M7MB0Ner\nmJ6JiPMiojkijoyIPwL2dxXTUuBESZMlDQdmkp3HKLWY7AsAIQudByIiyC6pPUXSyDw4zgQe7+Nr\nMjOzAXAwvyh3xb4683MKl5EN9quAuyJipaR5ks7LN7sJaJK0On+8ufm+LwPfIAuZFcDyiPjJQdRq\nZmb9pOwD+wHsKK2NiIn73/LQaGtri/b29kqXYWZ2WJG0LCLaUn0HcwRxYMliZmaHhX1+3bekV0gH\ngYCGQioyM7NBYZ8BERGNh6oQMzMbXA5misnMzIYwB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmS\nA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAz\nsyQHhJmZJTkgzMwsqdCAkDRd0pOSVkuam+gfIenOvP8hSZPK+o+TtEXSlUXWaWZmPRUWEJJqgAXA\nuUArMEtSa9lmlwAvR8QU4HrgurL+bwD3FVWjmZn1rsgjiKnA6ohYExE7gEXAjLJtZgC35st3A9Mk\nCUDSHwG/B1YWWKOZmfWiyIA4Flhbst6RtyW3iYguYBPQJGk08AXgmn09gaQ5ktolta9fv37ACjcz\ns8F7kvpq4PqI2LKvjSJiYUS0RURbc3PzoanMzKxK1Bb42M8BE0vWW/K21DYdkmqBsUAn8E7gfElf\nBcYBuyVti4j5BdZrZmYligyIpcCJkiaTBcFM4JNl2ywGLgJ+BZwPPBARAfyX7g0kXQ1scTiYmR1a\nhQVERHRJugxYAtQAN0fESknzgPaIWAzcBNwuaTXwElmImJnZIKDsA/vhr62tLdrb2ytdhpnZYUXS\nsohoS/UN1pPUZmZWYQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkO\nCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszM\nkhwQZmaW5IAwM7MkB4SZmSUVGhCSpkt6UtJqSXMT/SMk3Zn3PyRpUt7+AUnLJD2W359VZJ1mZtZT\nYQEhqQZYAJwLtAKzJLWWbXYJ8HJETAGuB67L2zcAH42IU4CLgNuLqtPMzNKKPIKYCqyOiDURsQNY\nBMwo22YGcGu+fDcwTZIi4pGIeD5vXwk0SBpRYK1mZlamyIA4Flhbst6RtyW3iYguYBPQVLbNx4Dl\nEbG9/AkkzZHULql9/fr1A1a4mZkN8pPUkk4mm3b681R/RCyMiLaIaGtubj60xZmZDXFFBsRzwMSS\n9Za8LbmNpFpgLNCZr7cA9wKfiojfFVinmZklFBkQS4ETJU2WNByYCSwu22Yx2UlogPOBByIiJI0D\nfgLMjYh/L7BGMzPrRWEBkZ9TuAxYAqwC7oqIlZLmSTov3+wmoEnSauAKoPtS2MuAKcCXJK3Ib0cW\nVauZmfWkiKh0DQOira0t2tvbK12GmdlhRdKyiGhL9Q3qk9RmZlY5DggzM0tyQJiZWZIDwszMkhwQ\nZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZkl\nOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzs6RCA0LSdElPSlotaW6if4SkO/P+\nhyRNKun7Yt7+pKQPFlmnmZn1VFhASKoBFgDnAq3ALEmtZZtdArwcEVOA64Hr8n1bgZnAycB04H/n\nj2dmZodIbYGPPRVYHRFrACQtAmYAj5dsMwO4Ol++G5gvSXn7oojYDvxe0ur88X410EVufG0HH/vW\ngwP9sAcse/mVNziqMLO+OOnoMdw467QBf9wiA+JYYG3Jegfwzt62iYguSZuAprz912X7Hlv+BJLm\nAHMAjjvuuAMqsmaYOOnoMQe074CLSheQicFSiJn1ycTxDYU8bpEBUbiIWAgsBGhrazugUa2xvo4F\nnzx9QOsyMxsKijxJ/RwwsWS9JW9LbiOpFhgLdPZxXzMzK1CRAbEUOFHSZEnDyU46Ly7bZjFwUb58\nPvBARETePjO/ymkycCLwcIG1mplZmcKmmPJzCpcBS4Aa4OaIWClpHtAeEYuBm4Db85PQL5GFCPl2\nd5Gd0O4C/iIidhVVq5mZ9aTsA/vhr62tLdrb2ytdhpnZYUXSsohoS/X5L6nNzCzJAWFmZkkOCDMz\nS3JAmJlZ0pA5SS1pPfDMQTzEBGDDAJVzuPN7sTe/H3vz+7HHUHgvjo+I5lTHkAmIgyWpvbcz+dXG\n78Xe/H7sze/HHkP9vfAUk5mZJTkgzMwsyQGxx8JKFzCI+L3Ym9+Pvfn92GNIvxc+B2FmZkk+gjAz\nsyQHhJmZJVV9QEiaLulJSaslza10PZUkaaKk/yPpcUkrJX2+0jVVmqQaSY9I+udK11JpksZJulvS\nE5JWSfrDStdUSZL+W/7/5LeSfiipvtI1DbSqDghJNcAC4FygFZglqbWyVVVUF/BXEdEKvAv4iyp/\nPwA+D6yqdBGDxA3AzyLiJODtVPH7IulY4HKgLSLeSvaTBjMrW9XAq+qAAKYCqyNiTUTsABYBMypc\nU8VExLqIWJ4vv0I2APT4LfBqIakF+DDw3UrXUmmSxgLvJfsNFyJiR0RsrGxVFVcLNOS/hjkSeL7C\n9Qy4ag+IY4G1JesdVPGAWErSJOA04KHKVlJR3wT+Bthd6UIGgcnAeuCWfMrtu5JGVbqoSomI54Cv\nAc8C64BNEfHzylY18Ko9ICxB0mjgHuAvI2JzpeupBEkfAV6MiGWVrmWQqAVOB74VEacBrwJVe85O\n0niy2YbJwDHAKEkXVraqgVftAfEcMLFkvSVvq1qS6sjC4fsR8aNK11NBZwDnSXqabOrxLEl3VLak\niuoAOiKi+4jybrLAqFZnA7+PiPURsRP4EfDuCtc04Ko9IJYCJ0qaLGk42UmmxRWuqWIkiWyOeVVE\nfKPS9VRSRHwxIloiYhLZv4sHImLIfULsq4h4AVgr6c150zSy34yvVs8C75I0Mv9/M40heNK+ttIF\nVFJEdEm6DFhCdhXCzRGxssJlVdIZwJ8Cj0lakbf994j4aQVrssHjc8D38w9Ta4DZFa6nYiLiIUl3\nA8vJrv57hCH4tRv+qg0zM0uq9ikmMzPrhQPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzPpB0i5JK0pu\nA/bXxJImSfrtQD2e2cGq6r+DMDsAWyPi1EoXYXYo+AjCbABIelrSVyU9JulhSVPy9kmSHpD0qKR/\nkXRc3n6UpHsl/Sa/dX9NQ42k7+S/M/BzSQ0Ve1FW9RwQZv3TUDbFdEFJ36aIOAWYT/ZNsAA3ArdG\nxNuA7wN/n7f/PfCvEfF2su806v4L/hOBBRFxMrAR+FjBr8esV/5LarN+kLQlIkYn2p8GzoqINfkX\nHr4QEU2SNgBHR8TOvH1dREyQtB5oiYjtJY8xCbg/Ik7M178A1EXE3xb/ysx68hGE2cCJXpb7Y3vJ\n8i58ntAqyAFhNnAuKLn/Vb78IHt+ivJPgF/my/8CfBZe/93rsYeqSLO+8qcTs/5pKPmmW8h+o7n7\nUtfxkh4lOwqYlbd9juxX2P6a7BfZur8B9fPAQkmXkB0pfJbsl8nMBg2fgzAbAPk5iLaI2FDpWswG\niqeYzMwsyUcQZmaW5CMIMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzpP8P1xAZ1UXsGG0AAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuMFT3Rc29GL",
        "colab_type": "code",
        "outputId": "a6161005-1835-4e77-daf3-0c60a5777f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDDPErg74EXy",
        "colab_type": "code",
        "outputId": "240305f4-2d03-4777-9473-d1cb9600e4be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140185262047696 -->\n<g class=\"node\" id=\"node1\">\n<title>140185262047696</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_7_input: InputLayer</text>\n</g>\n<!-- 140185262099312 -->\n<g class=\"node\" id=\"node2\">\n<title>140185262099312</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_7: Dense</text>\n</g>\n<!-- 140185262047696&#45;&gt;140185262099312 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140185262047696-&gt;140185262099312</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140185262225616 -->\n<g class=\"node\" id=\"node3\">\n<title>140185262225616</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_8: Dense</text>\n</g>\n<!-- 140185262099312&#45;&gt;140185262225616 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140185262099312-&gt;140185262225616</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140185262144368 -->\n<g class=\"node\" id=\"node4\">\n<title>140185262144368</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_9: Dense</text>\n</g>\n<!-- 140185262225616&#45;&gt;140185262144368 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140185262225616-&gt;140185262144368</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psmGp3fJ4JnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}